{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Statistical modeling is the process of creating a simplified mathematical representation of a real-world system using statistical methods. These models aim to capture relationships between variables (e.g., interest rates and loan defaults) and quantify uncertainty (e.g., probability of default). The models are built using data and validated to ensure they generalize well to new, unseen data.**"
      ],
      "metadata": {
        "id": "EH9OhXSkenWG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Descriptive Models\n",
        "\n",
        "Purpose: Summarize and describe data without making predictions.\n",
        "Examples: Measures of central tendency (mean, median), dispersion (variance, standard deviation), and visualizations (histograms, box plots).\n",
        ".\n",
        "\n",
        "2. Inferential Models\n",
        "\n",
        "Purpose: Draw conclusions about a population based on sample data, often using hypothesis testing or confidence intervals.\n",
        "Examples: T-tests, ANOVA, chi-square tests.\n",
        "\n",
        "\n",
        "3. Predictive Models\n",
        "\n",
        "Purpose: Predict future outcomes or classify observations based on historical data.\n",
        "Subtypes:\n",
        "\n",
        "Regression Models:\n",
        "\n",
        "Linear Regression: Models a linear relationship between continuous dependent and independent variables (e.g., predicting stock returns based on market indicators).\n",
        "Logistic Regression: Predicts binary outcomes (e.g., default vs. non-default on a loan).\n",
        "Generalized Linear Models (GLM): Extends regression for non-normal distributions (e.g., Poisson regression for count data like transaction frequency).\n",
        "\n",
        "\n",
        "Time Series Models:\n",
        "\n",
        "ARIMA (Auto-Regressive Integrated Moving Average): Models time-dependent data (e.g., forecasting stock prices or interest rates).\n",
        "GARCH (Generalized Autoregressive Conditional Heteroskedasticity): Models volatility in financial time series (e.g., stock price volatility).\n",
        "\n",
        "\n",
        "Machine Learning Models: Advanced predictive models like decision trees, random forests, or neural networks, often used in fraud detection or credit scoring.\n",
        "\n",
        "4. Prescriptive Models\n",
        "\n",
        "Purpose: Provide recommendations or optimal decisions based on data and constraints.\n",
        "Examples: Optimization models (e.g., linear programming for portfolio optimization), simulation models (e.g., Monte Carlo for risk analysis).\n",
        "\n",
        "\n",
        "5. Bayesian Models\n",
        "\n",
        "Purpose: Incorporate prior knowledge or beliefs into the model, updating predictions as new data arrives.\n",
        "Examples: Bayesian regression, Bayesian networks.\n",
        "\n",
        "\n",
        "6. Non-Parametric and Non-Parametric Models\n",
        "\n",
        "Parametric models assume that the data follows a specific distribution or functional form, characterized by a fixed number of parameters. These parameters are estimated from the data, and the model’s structure is predefined (e.g., linear, logistic). The number of parameters does not grow with the size of the dataset.\n",
        "\n",
        "Non-parametric models do not assume a specific functional form or distribution for the data. They are flexible and adapt to the data’s structure, with the complexity (e.g., number of parameters) growing with the dataset size.\n"
      ],
      "metadata": {
        "id": "SD7hBnDnfmNi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Random Forest\n",
        "\n",
        "1. Ensemble learning algorithm ( Bagging ) [ Many base learner models ]\n",
        "2. Multiple decision Trees\n",
        "3. Data is divided into random subsets ( Row sampling and feature sampling with replacement )\n",
        "4. Aggregation (Voting) [ Majority : Classifier , Averaging : Regresor ]\n",
        "5. How many decision trees ? [ Hyperparameter tuning ]\n"
      ],
      "metadata": {
        "id": "mrFnUmGskrsg"
      }
    }
  ]
}